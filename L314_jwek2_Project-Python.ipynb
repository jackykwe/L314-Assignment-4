{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d4ba52-325f-4e69-b55a-5045fe429039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sympy as sp\n",
    "import scipy\n",
    "from tqdm.auto import tqdm, trange\n",
    "import PIL\n",
    "import gc\n",
    "import datetime\n",
    "import numba as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd1aa23-0abe-491d-98d4-2b776a8aebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(x, x_min, x_max):\n",
    "    return max(x_min, min(x_max, x))\n",
    "    \n",
    "def generate_y_quantisation_table_given_quality(f):\n",
    "    # f is quality in range 1..100 (technically cjpeg accepts 0 too but that's converted to 1)\n",
    "    assert f in range(1, 101)\n",
    "    standard_y_quantisation_table = np.array([\n",
    "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "        [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "    ])\n",
    "    scaling_factor = 5000 // f if f < 50 else 200 - 2 * f\n",
    "    return np.vectorize(clamp)((standard_y_quantisation_table * scaling_factor + 50) // 100, 1, 255)\n",
    "\n",
    "# def generate_cbcr_quantisation_table_given_quality(f):\n",
    "#     # f is quality in range 1..100 (technically cjpeg accepts 0 too but that's converted to 1)\n",
    "#     assert f in range(1, 101)\n",
    "#     standard_cbcr_quantisation_table = np.array([\n",
    "#         [17, 18, 24, 47, 99, 99, 99, 99],\n",
    "#         [18, 21, 26, 66, 99, 99, 99, 99],\n",
    "#         [24, 26, 56, 99, 99, 99, 99, 99],\n",
    "#         [47, 66, 99, 99, 99, 99, 99, 99],\n",
    "#         [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "#         [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "#         [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "#         [99, 99, 99, 99, 99, 99, 99, 99]\n",
    "#     ])\n",
    "#     scaling_factor = 5000 // f if f < 50 else 200 - 2 * f\n",
    "#     return np.vectorize(clamp)((standard_cbcr_quantisation_table * scaling_factor + 50) // 100, 1, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b4a979-999f-44ba-b961-a6ecab5c161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.array([\n",
    "    [-2 ** 23, 2 ** 10, 2 ** 10, 2 ** 10, 0, 2 ** 10, 2 ** 10, 2 ** 10],\n",
    "    [-2 ** 23, 2 ** 10, 2 ** 10, 2 ** 10, 0, 2 ** 10, 2 ** 10, 2 ** 10],\n",
    "    [-2 ** 23, 2 ** 10, 2 ** 10, 2 ** 10, 0, 2 ** 10, 2 ** 10, 2 ** 10],\n",
    "    [-2 ** 23, 2 ** 10, 2 ** 10, 2 ** 10, 0, 2 ** 10, 2 ** 10, 2 ** 10],\n",
    "    [-2 ** 23, 2 ** 10, 2 ** 10, 2 ** 10, 0, 2 ** 10, 2 ** 10, 2 ** 10],\n",
    "    [-2 ** 23, 2 ** 10, 2 ** 10, 2 ** 10, 0, 2 ** 10, 2 ** 10, 2 ** 10],\n",
    "    [-2 ** 23, 2 ** 10, 2 ** 10, 2 ** 10, 0, 2 ** 10, 2 ** 10, 2 ** 10],\n",
    "    [-2 ** 23, 2 ** 10, 2 ** 10, 2 ** 10, 0, 2 ** 10, 2 ** 10, 2 ** 10]\n",
    "])\n",
    "T = np.array([\n",
    "    [8192, 11363, 10703, 9633, 8192, 6437, 4433, 2260],\n",
    "    [8192, 9633, 4433, -2259, -8192, -11362, -10704, -6436],\n",
    "    [8192, 6437, -4433, -11362, -8192, 2261, 10704, 9633],\n",
    "    [8192, 2260, -10703, -6436, 8192, 9633, -4433, -11363],\n",
    "    [8192, -2260, -10703, 6436, 8192, -9633, -4433, 11363],\n",
    "    [8192, -6437, -4433, 11362, -8192, -2261, 10704, -9633],\n",
    "    [8192, -9633, 4433, 2259, -8192, 11362, -10704, 6436],\n",
    "    [8192, -11363, 10703, -9633, 8192, -6437, 4433, -2260]\n",
    "])\n",
    "def ijg_dct(X):\n",
    "    assert X.shape == (8, 8)\n",
    "    # the final division by 8 is technically combined with quantisation\n",
    "    # but quantisation is not done here\n",
    "    # I take C's right shift to round down towards negative infinity\n",
    "    return (((T.T @ (((X @ T) + V) >> 11)) + (2 ** 14)) >> 15) >> 3\n",
    "    # return np.floor(np.floor(((T.T @ np.floor(((X @ T) + V) / (2 ** 11))) + (2 ** 14)) / (2 ** 15)) / 8)  # Equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83980b16-6783-42e4-b71e-185f5fc8db25",
   "metadata": {},
   "source": [
    "# MLE Estimation of Quantisation Table\n",
    "There is no need for arbitrary precision arithmetic here, unlike in Exact Recompression. Standard Numpy arrays may be used instead of Sympy number types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50ee47b9-9cbb-48b1-bed4-e9833951a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factors_of(x):\n",
    "    return [i for i in range(1, x + 1) if x % i == 0]\n",
    "\n",
    "def generate_D(x):\n",
    "    if x in (0, 4):\n",
    "        return 2\n",
    "    elif x in (2, 6):\n",
    "        return np.sqrt(2)\n",
    "        # return 2 * np.cos(np.pi / 4)\n",
    "    else:\n",
    "        return np.sqrt(2) * np.cos(np.pi / 8)\n",
    "        # return 2 * np.cos(np.pi / 4) * np.cos(np.pi / 8)\n",
    "def generate_B(m, n):\n",
    "    # width of the Gaussians around each peak in the model\n",
    "    return generate_D(m) * generate_D(n)\n",
    "B = np.array([generate_B(m, n) for m in range(8) for n in range(8)]).reshape(8, 8)  # all the B(m, n)\n",
    "\n",
    "def pdf_G(evalat, centre, B_mn):\n",
    "    # normalisation Z doesn't matter since it's constant for a particular mn\n",
    "    if np.abs(evalat - centre) > B_mn:\n",
    "        return 0\n",
    "    return np.exp(-6 * ((evalat - centre) ** 2))\n",
    "\n",
    "def pdf_Laplace(evalat, b_MLE):\n",
    "    return np.exp(-np.abs(evalat) / b_MLE) / (2 * b_MLE)\n",
    "\n",
    "def argmax_summand(yprime_mn_s, q_candidate, B_mn, b_MLE):\n",
    "    # yprime_mn_s: the yprime_mn_s value, a DCT coefficient we obtain after applying ijg_dct(), used in integral bounds\n",
    "    # q_candidate: one of the summands in the argmax\n",
    "    # B_mn: for generating k_to_sum, which is used for computing the truncated Gaussian PDF, pdf_G\n",
    "    # b_MLE: for computing the Laplace PDF, pdf_Laplace\n",
    "    k_to_sum = list(range(\n",
    "        int(np.trunc(-2 * B_mn / q_candidate)), \n",
    "        int(np.trunc(2 * B_mn / q_candidate)) + 1\n",
    "    ))  # integers -2B/q <= k <= 2B/q\n",
    "    def integrand(y):\n",
    "        r = np.round(y / q_candidate)\n",
    "        return np.sum([pdf_G(y, (r + k) * q_candidate, B_mn) for k in k_to_sum]) * pdf_Laplace(r * q_candidate, b_MLE)\n",
    "        # return np.sum([pdf_G(y, (r + k) * q_candidate, B_mn) for k in k_to_sum]) * pdf_Laplace(r * q_candidate, b_MLE)\n",
    "    return np.log(scipy.integrate.quad(integrand, yprime_mn_s - 0.5, yprime_mn_s + 0.5)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f9229-4eb0-43a6-9898-f846435f496c",
   "metadata": {},
   "source": [
    "## `test2.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f5cc7b-b50c-433c-a2cc-70dec260c9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 190512 blocks before filtering\n",
      "Total 170428 blocks after filtering\n",
      "Applying IJG DCT on each block...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994d1950de234ba1835b9215cd829581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name = \"test2\"  # test2 or test3\n",
    "image = PIL.Image.open(f\"{file_name}.png\")\n",
    "y_channel = np.asarray(image)\n",
    "\n",
    "H, W = y_channel.shape\n",
    "assert H % 8 == 0 and W % 8 == 0\n",
    "count_blocks_vertical = H // 8\n",
    "count_blocks_horizontal = W // 8\n",
    "\n",
    "blocks = [\n",
    "    y_channel[(8 * block_i):(8 + 8 * block_i), (8 * block_j):(8 + 8 * block_j)] \n",
    "    for block_i in range(count_blocks_vertical) \n",
    "    for block_j in range(count_blocks_horizontal)\n",
    "]\n",
    "print(f\"Total {len(blocks)} blocks before filtering\")\n",
    "blocks = [b for b in blocks if np.min(b) != 0 and np.max(b) != 255 and np.min(b) != np.max(b)]\n",
    "print(f\"Total {len(blocks)} blocks after filtering\")\n",
    "\n",
    "# perform DCT on each block\n",
    "print(\"Applying IJG DCT on each block...\")\n",
    "yprime_blocks = [ijg_dct(block) for block in tqdm(blocks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25153a1f-7c88-446a-8ea3-726fd0576c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  6,  6,  9, 13, 22, 29, 33],\n",
       "       [ 7,  7,  8, 11, 15, 32, 34, 31],\n",
       "       [ 8,  7,  9, 13, 22, 32, 39, 30],\n",
       "       [ 8, 10, 12, 16, 28, 50, 46,  0],\n",
       "       [10, 12, 21, 31, 38,  0,  0,  0],\n",
       "       [13, 20, 31, 36,  0,  0,  0,  0],\n",
       "       [27, 36, 44, 49,  0,  0,  0,  0],\n",
       "       [40, 52, 53,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell's values were obtained manually from inspecting the histograms\n",
    "# Q, Q + 1 and Q - 1\n",
    "highest_peaks_outside_main_lobe = {\n",
    "    (0, 0): 0,  # skip; does not conform to Normal distribution. Peak at 9\n",
    "    (0, 1): 6,\n",
    "    (0, 2): 6,\n",
    "    (0, 3): 9,\n",
    "    (0, 4): 13,\n",
    "    (0, 5): 22,\n",
    "    (0, 6): 29,\n",
    "    (0, 7): 33,\n",
    "    (1, 0): 7,\n",
    "    (1, 1): 7,\n",
    "    (1, 2): 8,\n",
    "    (1, 3): 11,\n",
    "    (1, 4): 15,\n",
    "    (1, 5): 32,\n",
    "    (1, 6): 34,\n",
    "    (1, 7): 31,\n",
    "    (2, 0): 8,\n",
    "    (2, 1): 7,\n",
    "    (2, 2): 9,\n",
    "    (2, 3): 13,\n",
    "    (2, 4): 22,\n",
    "    (2, 5): 32,\n",
    "    (2, 6): 39,\n",
    "    (2, 7): 30,\n",
    "    (3, 0): 8,\n",
    "    (3, 1): 10,\n",
    "    (3, 2): 12,\n",
    "    (3, 3): 16,\n",
    "    (3, 4): 28,\n",
    "    (3, 5): 50,\n",
    "    (3, 6): 46,\n",
    "    (3, 7): 0,  # no peak detected outside main lobe\n",
    "    (4, 0): 10,\n",
    "    (4, 1): 12,\n",
    "    (4, 2): 21,\n",
    "    (4, 3): 31,\n",
    "    (4, 4): 38,\n",
    "    (4, 5): 0,  # no peak detected outside main lobe\n",
    "    (4, 6): 0,  # no peak detected outside main lobe\n",
    "    (4, 7): 0,  # no peak detected outside main lobe\n",
    "    (5, 0): 13,\n",
    "    (5, 1): 20,\n",
    "    (5, 2): 31,\n",
    "    (5, 3): 36,\n",
    "    (5, 4): 0,  # no peak detected outside main lobe\n",
    "    (5, 5): 0,  # no peak detected outside main lobe\n",
    "    (5, 6): 0,  # no peak detected outside main lobe\n",
    "    (5, 7): 0,  # no peak detected outside main lobe\n",
    "    (6, 0): 27,\n",
    "    (6, 1): 36,\n",
    "    (6, 2): 44,\n",
    "    (6, 3): 49,\n",
    "    (6, 4): 0,  # no peak detected outside main lobe\n",
    "    (6, 5): 0,  # no peak detected outside main lobe\n",
    "    (6, 6): 0,  # no peak detected outside main lobe\n",
    "    (6, 7): 0,  # no peak detected outside main lobe\n",
    "    (7, 0): 40,\n",
    "    (7, 1): 52,\n",
    "    (7, 2): 53,\n",
    "    (7, 3): 0,  # no peak detected outside main lobe\n",
    "    (7, 4): 0,  # no peak detected outside main lobe ? probably not a peak at 3\n",
    "    (7, 5): 0,  # no peak detected outside main lobe\n",
    "    (7, 6): 0,  # no peak detected outside main lobe\n",
    "    (7, 7): 0,  # no peak detected outside main lobe\n",
    "}\n",
    "argmax_q_candidates = {\n",
    "    k: list(set(factors_of(v - 1) + factors_of(v) + factors_of(v + 1)))\n",
    "    for k, v in highest_peaks_outside_main_lobe.items() if v != 0\n",
    "}\n",
    "# test2.png likely compressed with lowest setting f=72\n",
    "# because this matrix looks very much like the Y quantisation table for f=72\n",
    "np.array(list(highest_peaks_outside_main_lobe.values())).reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43e69429-3580-4ab1-bad6-9b3027d02e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  6,  6,  9, 13, 22, 29, 34],\n",
       "       [ 7,  7,  8, 11, 15, 32, 34, 31],\n",
       "       [ 8,  7,  9, 13, 22, 32, 39, 31],\n",
       "       [ 8, 10, 12, 16, 29, 49, 45, 35],\n",
       "       [10, 12, 21, 31, 38, 61, 58, 43],\n",
       "       [13, 20, 31, 36, 45, 58, 63, 52],\n",
       "       [27, 36, 44, 49, 58, 68, 67, 57],\n",
       "       [40, 52, 53, 55, 63, 56, 58, 55]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_y_quantisation_table_given_quality(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8864d-99c7-4971-b8f8-34533ed6926b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf648f088674c84b9d35b28a43b9020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1864c37674374ff788065aae6e35a26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_MLE[0, 1] = 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97c042a3ab94bd5a801b0fee40dcd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8185de7c3c447e9fbb02602a25ae63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_MLE = np.full((8, 8), None)\n",
    "for m in trange(8):\n",
    "    for n in trange(8, leave=False):\n",
    "        if (m, n) not in argmax_q_candidates:\n",
    "            continue  # skip for reasons explained in argmax_candidates\n",
    "            \n",
    "        B_mn = B[m, n]\n",
    "        yprime_mn_ss = ([block[m, n] for block in yprime_blocks])  # all the yprime_mn across all blocks (i.e. collection of all DCT coefficients (m, n) from across all blocks)\n",
    "        b_MLE = np.mean(np.abs(yprime_mn_ss))  # MLE estimator for the scale parameter in the underlying Laplace distribution for DCT coefficient (m, n)\n",
    "\n",
    "        argmax_q = None\n",
    "        max_q = None\n",
    "        for q_candidate in tqdm(argmax_q_candidates[(m, n)], leave=False):\n",
    "            sum = 0\n",
    "            for yprime_mn_s in tqdm(yprime_mn_ss, leave=False):\n",
    "                sum += argmax_summand(yprime_mn_s, q_candidate, B_mn, b_MLE)\n",
    "            if max_q is None or sum > max_q:\n",
    "                max_q = sum\n",
    "                argmax_q = q_candidate\n",
    "            \n",
    "        q_MLE[m, n] = argmax_q\n",
    "        print(f\"q_MLE[{m}, {n}] = {argmax_q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7dcd5c-f7a1-4f91-b4b0-1c59a8e435d9",
   "metadata": {},
   "source": [
    "## `test3.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c081dd-a58e-47aa-9d67-3fbdc6d29c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test3\"  # test2 or test3\n",
    "image = PIL.Image.open(f\"{file_name}.png\")\n",
    "y_channel = np.asarray(image)\n",
    "\n",
    "H, W = y_channel.shape\n",
    "assert H % 8 == 0 and W % 8 == 0\n",
    "count_blocks_vertical = H // 8\n",
    "count_blocks_horizontal = W // 8\n",
    "\n",
    "blocks = [\n",
    "    y_channel[(8 * block_i):(8 + 8 * block_i), (8 * block_j):(8 + 8 * block_j)] \n",
    "    for block_i in range(count_blocks_vertical) \n",
    "    for block_j in range(count_blocks_horizontal)\n",
    "]\n",
    "print(f\"Total {len(blocks)} blocks before filtering\")\n",
    "blocks = [b for b in blocks if np.min(b) != 0 and np.max(b) != 255 and np.min(b) != np.max(b)]\n",
    "print(f\"Total {len(blocks)} blocks after filtering\")\n",
    "\n",
    "# perform DCT on each block\n",
    "print(\"Applying IJG DCT on each block...\")\n",
    "yprime_blocks = [ijg_dct(block) for block in tqdm(blocks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aa169e-16a0-451c-aa41-91421862046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell's values were obtained manually from inspecting the histograms\n",
    "# Q, Q + 1 and Q - 1\n",
    "highest_peaks_outside_main_lobe = {\n",
    "    (0, 0): 0,  # skip; does not conform to Normal distribution. peak at 10\n",
    "    (0, 1): 7,\n",
    "    (0, 2): 6,\n",
    "    (0, 3): 10,\n",
    "    (0, 4): 14,\n",
    "    (0, 5): 24,\n",
    "    (0, 6): 31,\n",
    "    (0, 7): 37,\n",
    "    (1, 0): 7,\n",
    "    (1, 1): 7,\n",
    "    (1, 2): 8,\n",
    "    (1, 3): 11,\n",
    "    (1, 4): 16,\n",
    "    (1, 5): 35,\n",
    "    (1, 6): 35,\n",
    "    (1, 7): 0,  # no peak detected outside main lobe\n",
    "    (2, 0): 8,\n",
    "    (2, 1): 8,\n",
    "    (2, 2): 10,\n",
    "    (2, 3): 14,\n",
    "    (2, 4): 24,\n",
    "    (2, 5): 34,\n",
    "    (2, 6): 41,\n",
    "    (2, 7): 34,\n",
    "    (3, 0): 8,\n",
    "    (3, 1): 10,\n",
    "    (3, 2): 13,\n",
    "    (3, 3): 17,\n",
    "    (3, 4): 31,\n",
    "    (3, 5): 49,\n",
    "    (3, 6): 0,  # no peak detected outside main lobe ? probably not a peak at 4\n",
    "    (3, 7): 0,  # no peak detected outside main lobe\n",
    "    (4, 0): 11,\n",
    "    (4, 1): 13,\n",
    "    (4, 2): 22,\n",
    "    (4, 3): 34,\n",
    "    (4, 4): 40,\n",
    "    (4, 5): 0,  # no peak detected outside main lobe ? probably not a peak at 3\n",
    "    (4, 6): 0,  # no peak detected outside main lobe\n",
    "    (4, 7): 0,  # no peak detected outside main lobe\n",
    "    (5, 0): 14,\n",
    "    (5, 1): 21,\n",
    "    (5, 2): 33,\n",
    "    (5, 3): 35,\n",
    "    (5, 4): 0,  # no peak detected outside main lobe\n",
    "    (5, 5): 0,  # no peak detected outside main lobe\n",
    "    (5, 6): 0,  # no peak detected outside main lobe\n",
    "    (5, 7): 0,  # no peak detected outside main lobe\n",
    "    (6, 0): 29,\n",
    "    (6, 1): 38,\n",
    "    (6, 2): 0,  # no peak detected outside main lobe\n",
    "    (6, 3): 0,  # no peak detected outside main lobe\n",
    "    (6, 4): 0,  # no peak detected outside main lobe\n",
    "    (6, 5): 0,  # no peak detected outside main lobe\n",
    "    (6, 6): 0,  # no peak detected outside main lobe\n",
    "    (6, 7): 0,  # no peak detected outside main lobe  ? probably not a peak at 3\n",
    "    (7, 0): 43,  # suspicious... non-symmetric. small peak at 35\n",
    "    (7, 1): 0,  # no peak detected outside main lobe\n",
    "    (7, 2): 0,  # no peak detected outside main lobe\n",
    "    (7, 3): 0,  # no peak detected outside main lobe\n",
    "    (7, 4): 0,  # no peak detected outside main lobe ? probably not a peak at -4\n",
    "    (7, 5): 0,  # no peak detected outside main lobe\n",
    "    (7, 6): 0,  # no peak detected outside main lobe\n",
    "    (7, 7): 0,  # no peak detected outside main lobe\n",
    "}\n",
    "argmax_q_candidates = {\n",
    "    k: list(set(factors_of(v - 1) + factors_of(v) + factors_of(v + 1)))\n",
    "    for k, v in highest_peaks_outside_main_lobe.items() if v != 0\n",
    "}\n",
    "# test3.png likely compressed with lowest setting f=70\n",
    "# because this matrix looks very much like the Y quantisation table for f=70\n",
    "np.array(list(highest_peaks_outside_main_lobe.values())).reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a461a7-f94c-4818-8762-2b54a5dff203",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_y_quantisation_table_given_quality(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ce1f4-cfe4-4f60-94db-8ca7a79d0938",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_y_quantisation_table_given_quality(76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99335b0b-81a9-473c-9daa-9b5595be387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_MLE = np.full((8, 8), None)\n",
    "for m in trange(8):\n",
    "    for n in trange(8, leave=False):\n",
    "        if (m, n) not in argmax_q_candidates:\n",
    "            continue  # skip for reasons explained in argmax_candidates\n",
    "            \n",
    "        B_mn = B[m, n]\n",
    "        yprime_mn_ss = [block[m, n] for block in yprime_blocks]  # all the yprime_mn across all blocks (i.e. collection of all DCT coefficients (m, n) from across all blocks)\n",
    "        b_MLE = np.mean(np.abs(yprime_mn_ss))  # MLE estimator for the scale parameter in the underlying Laplace distribution for DCT coefficient (m, n)\n",
    "\n",
    "        argmax_q = None\n",
    "        max_q = None\n",
    "        for q_candidate in tqdm(argmax_q_candidates[(m, n)], leave=False):\n",
    "            sum = 0\n",
    "            for yprime_mn_s in tqdm(yprime_mn_ss, leave=False):\n",
    "                sum += argmax_summand(yprime_mn_s, q_candidate, B_mn, b_MLE)\n",
    "            if max_q is None or sum > max_q:\n",
    "                max_q = sum\n",
    "                argmax_q = q_candidate\n",
    "            \n",
    "        q_MLE[m, n] = argmax_q\n",
    "        print(f\"q_MLE[{m}, {n}] = {argmax_q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854e5fd-f78d-4840-91e6-1185f0e74663",
   "metadata": {},
   "source": [
    "The following was tried (maximising the joint probability as mentioned in the paper's $\\S IV$. However it's even slower than the above optimisation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c3323-31ab-4c73-aca0-7d7c5f774204",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test3\"  # test2 or test3\n",
    "image = PIL.Image.open(f\"{file_name}.png\")\n",
    "y_channel = np.asarray(image)\n",
    "\n",
    "H, W = y_channel.shape\n",
    "assert H % 8 == 0 and W % 8 == 0\n",
    "count_blocks_vertical = H // 8\n",
    "count_blocks_horizontal = W // 8\n",
    "\n",
    "blocks = [\n",
    "    y_channel[(8 * block_i):(8 + 8 * block_i), (8 * block_j):(8 + 8 * block_j)] \n",
    "    for block_i in range(count_blocks_vertical) \n",
    "    for block_j in range(count_blocks_horizontal)\n",
    "]\n",
    "print(f\"Total {len(blocks)} blocks before filtering\")\n",
    "blocks = [b for b in blocks if np.min(b) != 0 and np.max(b) != 255 and np.min(b) != np.max(b)]\n",
    "print(f\"Total {len(blocks)} blocks after filtering\")\n",
    "\n",
    "# perform DCT on each block\n",
    "print(\"Applying IJG DCT on each block...\")\n",
    "yprime_blocks = [ijg_dct(block) for block in tqdm(blocks)]\n",
    "\n",
    "f_min = 70\n",
    "argmax_f = None\n",
    "max_f = None\n",
    "for f_candidate in trange(f_min, 101):\n",
    "    q = generate_y_quantisation_table_given_quality(f_candidate)\n",
    "    sum = 0\n",
    "    for m in trange(8, leave=False):\n",
    "        for n in trange(8, leave=False):\n",
    "            q_mn = q[m, n]\n",
    "            B_mn = B[m, n]\n",
    "            yprime_mn_ss = [block[m, n] for block in yprime_blocks]  # all the yprime_mn across all blocks (i.e. collection of all DCT coefficients (m, n) from across all blocks)\n",
    "            b_MLE = np.mean(np.abs(yprime_mn_ss))  # MLE estimator for the scale parameter in the underlying Laplace distribution for DCT coefficient (m, n)\n",
    "            for yprime_mn_s in tqdm(yprime_mn_ss, leave=False):\n",
    "                sum += argmax_summand(yprime_mn_s, q_mn, B_mn, b_MLE)\n",
    "    if max_f is None or sum > max_f:\n",
    "        max_f = sum\n",
    "        argmax_f = f_candidate\n",
    "        print(f\"argmax_q = {argmax_q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b465e6b9-721e-436d-9b5d-972faba074d0",
   "metadata": {},
   "source": [
    "## `test1c.png`\n",
    "Similar code as for `test2.png` and `test3.png` can be used here. Just need to read the `test1c.png`, then perform mapping from $RGB$ to $YCbCr$, then obtain the $Y$-channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e26ffc-676e-4554-a057-49825084a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell's values were obtained manually from inspecting the histograms\n",
    "# Q, Q + 1 and Q - 1\n",
    "highest_peaks_outside_main_lobe = {\n",
    "    (0, 0): 0,  # skip; does not conform to Normal distribution. Peak at 9.\n",
    "    (0, 1): 6,\n",
    "    (0, 2): 6,\n",
    "    (0, 3): 9,\n",
    "    (0, 4): 14,  # suspicious... non-symmetric? small peak at -67, -53, -36, \n",
    "    (0, 5): 23,  # suspicious... non-symmetric. small peak at 12&13\n",
    "    (0, 6): 30,\n",
    "    (0, 7): 35,\n",
    "    (1, 0): 7,\n",
    "    (1, 1): 7,\n",
    "    (1, 2): 8,\n",
    "    (1, 3): 11,  # semi-suspicious... non-symmetric? small peaking out at 3&7 hmm...\n",
    "    (1, 4): 15,\n",
    "    (1, 5): 34,\n",
    "    (1, 6): 35,\n",
    "    (1, 7): 32,\n",
    "    (2, 0): 8,\n",
    "    (2, 1): 8,\n",
    "    (2, 2): 9,\n",
    "    (2, 3): 14,\n",
    "    (2, 4): 23,\n",
    "    (2, 5): 32,\n",
    "    (2, 6): 39,\n",
    "    (2, 7): 31,  # funny gap 31 33\n",
    "    (3, 0): 8,\n",
    "    (3, 1): 10,\n",
    "    (3, 2): 13,\n",
    "    (3, 3): 17,\n",
    "    (3, 4): 30,  # suspicious... non-symmetric. small peak at 22\n",
    "    (3, 5): 50,\n",
    "    (3, 6): 0,  # no peak detected outside main lobe ? probably not a peak at 3\n",
    "    (3, 7): 35,\n",
    "    (4, 0): 10,\n",
    "    (4, 1): 13,\n",
    "    (4, 2): 21,\n",
    "    (4, 3): 32,  # suspicious... non-symmetric. small peak at -7\n",
    "    (4, 4): 39,\n",
    "    (4, 5): 0,  # no peak detected outside main lobe ? probably not a peak at 3\n",
    "    (4, 6): 0,  # no peak detected outside main lobe\n",
    "    (4, 7): 0,  # no peak detected outside main lobe\n",
    "    (5, 0): 14,\n",
    "    (5, 1): 20,\n",
    "    (5, 2): 32,\n",
    "    (5, 3): 37,\n",
    "    (5, 4): 0,  # no peak detected outside main lobe ? probably not a peak at 5\n",
    "    (5, 5): 0,  # no peak detected outside main lobe\n",
    "    (5, 6): 0,  # no peak detected outside main lobe\n",
    "    (5, 7): 0,  # no peak detected outside main lobe ? probably not a peak at 3\n",
    "    (6, 0): 28,\n",
    "    (6, 1): 37,\n",
    "    (6, 2): 45,\n",
    "    (6, 3): 0,  # no peak detected outside main lobe\n",
    "    (6, 4): 0,  # no peak detected outside main lobe\n",
    "    (6, 5): 0,  # no peak detected outside main lobe\n",
    "    (6, 6): 0,  # no peak detected outside main lobe\n",
    "    (6, 7): 0,  # no peak detected outside main lobe \n",
    "    (7, 0): 42,\n",
    "    (7, 1): 53, \n",
    "    (7, 2): 0,  # no peak detected outside main lobe\n",
    "    (7, 3): 0,  # no peak detected outside main lobe\n",
    "    (7, 4): 0,  # no peak detected outside main lobe ? probably not a peak at -4\n",
    "    (7, 5): 0,  # no peak detected outside main lobe\n",
    "    (7, 6): 0,  # no peak detected outside main lobe\n",
    "    (7, 7): 0,  # no peak detected outside main lobe ? probably not a peak at -4\n",
    "}\n",
    "argmax_q_candidates = {\n",
    "    k: list(set(factors_of(v - 1) + factors_of(v) + factors_of(v + 1)))\n",
    "    for k, v in highest_peaks_outside_main_lobe.items() if v != 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e50a60-f5f2-4c36-a504-8127a2409144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1c.png likely compressed with lowest setting f=71\n",
    "# because this matrix looks very much like the Y quantisation table for f=71\n",
    "np.array(list(highest_peaks_outside_main_lobe.values())).reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbed6c3-7720-4b02-9ee6-f610fe41f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_y_quantisation_table_given_quality(71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5643f-504f-4ccc-9ef4-7fb3db2ed9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_y_quantisation_table_given_quality(78)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c50f4d-f69f-4c82-bfb9-4117b9297830",
   "metadata": {},
   "source": [
    "## `test2c.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80721a3-0691-4430-8ab4-a0f2b73d8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell's values were obtained manually from inspecting the histograms\n",
    "# Q, Q + 1 and Q - 1\n",
    "highest_peaks_outside_main_lobe = {\n",
    "    (0, 0): 0,  # skip; does not conform to Normal distribution. peak at 9\n",
    "    (0, 1): 6,\n",
    "    (0, 2): 6,\n",
    "    (0, 3): 9,\n",
    "    (0, 4): 13,\n",
    "    (0, 5): 22,\n",
    "    (0, 6): 29,\n",
    "    (0, 7): 34,  # semi-suspicious... non-symmetric? small peaking out at 28 hmm...\n",
    "    (1, 0): 7,\n",
    "    (1, 1): 7,\n",
    "    (1, 2): 8,\n",
    "    (1, 3): 11,\n",
    "    (1, 4): 15,\n",
    "    (1, 5): 32,\n",
    "    (1, 6): 34,\n",
    "    (1, 7): 31,\n",
    "    (2, 0): 8,\n",
    "    (2, 1): 7,\n",
    "    (2, 2): 9,\n",
    "    (2, 3): 13,\n",
    "    (2, 4): 22,\n",
    "    (2, 5): 32,\n",
    "    (2, 6): 39,\n",
    "    (2, 7): 31,\n",
    "    (3, 0): 8,\n",
    "    (3, 1): 10,\n",
    "    (3, 2): 12,\n",
    "    (3, 3): 16,\n",
    "    (3, 4): 29,\n",
    "    (3, 5): 49,\n",
    "    (3, 6): 46,\n",
    "    (3, 7): 35,\n",
    "    (4, 0): 10,\n",
    "    (4, 1): 12,\n",
    "    (4, 2): 21,\n",
    "    (4, 3): 31,\n",
    "    (4, 4): 37,  # or 39. (edit: quantisation table f=72 is 38)\n",
    "    (4, 5): 0,  # no peak detected outside main lobe\n",
    "    (4, 6): 0,  # no peak detected outside main lobe\n",
    "    (4, 7): 0,  # no peak detected outside main lobe\n",
    "    (5, 0): 13,\n",
    "    (5, 1): 20,\n",
    "    (5, 2): 31,\n",
    "    (5, 3): 36,\n",
    "    (5, 4): 0,  # no peak detected outside main lobe\n",
    "    (5, 5): 0,  # no peak detected outside main lobe ? probably not a peak at 3\n",
    "    (5, 6): 0,  # no peak detected outside main lobe\n",
    "    (5, 7): 0,  # no peak detected outside main lobe\n",
    "    (6, 0): 27,\n",
    "    (6, 1): 36,\n",
    "    (6, 2): 44,\n",
    "    (6, 3): 49,  # or 46. Around 47/48? (edit: quantisation table f=72 is 49)\n",
    "    (6, 4): 0,  # no peak detected outside main lobe ? probably not a peak at 3\n",
    "    (6, 5): 0,  # no peak detected outside main lobe\n",
    "    (6, 6): 0,  # no peak detected outside main lobe\n",
    "    (6, 7): 0,  # no peak detected outside main lobe ? probably not a peak at 3\n",
    "    (7, 0): 41,\n",
    "    (7, 1): 52,\n",
    "    (7, 2): 53,\n",
    "    (7, 3): 0,  # no peak detected outside main lobe\n",
    "    (7, 4): 0,  # no peak detected outside main lobe\n",
    "    (7, 5): 0,  # no peak detected outside main lobe\n",
    "    (7, 6): 0,  # no peak detected outside main lobe\n",
    "    (7, 7): 0,  # no peak detected outside main lobe\n",
    "}\n",
    "argmax_q_candidates = {\n",
    "    k: list(set(factors_of(v - 1) + factors_of(v) + factors_of(v + 1)))\n",
    "    for k, v in highest_peaks_outside_main_lobe.items() if v != 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9be1e8-1d78-4e6d-bffe-b7415f6e8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test2c.png likely compressed with lowest setting f=72\n",
    "# because this matrix looks very much like the Y quantisation table for f=72\n",
    "np.array(list(highest_peaks_outside_main_lobe.values())).reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e0054e-8e69-4a08-b375-6b6e96116e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_y_quantisation_table_given_quality(72)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a7a4a-f395-435a-ad09-281abb770fdc",
   "metadata": {},
   "source": [
    "# Exact Recompression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ac2f1-bc82-4ab9-b001-69ddfad3c23f",
   "metadata": {},
   "source": [
    "## 2.1 Colour-space conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1537da-6cbf-432d-9696-3479daabbd2f",
   "metadata": {},
   "source": [
    "### (a) Greyscale images entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ebf91-982d-474d-8073-7494a5b74243",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test3\"  # test2 or test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c97a7b-3129-41b9-9327-57f5683a8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(f\"{file_name}.png\")\n",
    "bar_y_channel = np.asarray(image)\n",
    "bar_y_channel = np.vectorize(lambda v: sp.FiniteSet(v))(Y_channel)  # sp.Interval(v, v) simplifies to sp.FiniteSet(v) and the latter is faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c8643d-e636-4d5d-a3ca-a11f8da5a8f9",
   "metadata": {},
   "source": [
    "### (b) Coloured images entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d4f40-e43c-4f17-95cb-fac475f4421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB values are represented with (24-bit) integers from 0 to 2^24 - 1.\n",
    "def clamp(x, x_min, x_max):\n",
    "    return max(x_min, min(x_max, x))\n",
    "    \n",
    "# We want to map each RGB value u_xy to the set of all YCbCr values ddot_v_xy that maps to u_xy via rgb_to_ycbcr.\n",
    "def ycbcr_int_to_rgb_int(ycbcr_int):\n",
    "    # assumes ycbcr_int is an integer in [0..2^24-1].\n",
    "    y = (ycbcr_int >> 16)\n",
    "    cb = (ycbcr_int >> 8) & 0xff\n",
    "    cr = ycbcr_int & 0xff\n",
    "    r = y + ((91881 * (cr - 128) + 32768) >> 16)\n",
    "    g = y + ((-22553 * (cb - 128) - 46802 * (cr - 128) + 32768) >> 16)\n",
    "    b = y + ((116130 * (cb - 128) + 32768) >> 16)\n",
    "    r = clamp(r, 0, 255)\n",
    "    g = clamp(g, 0, 255)\n",
    "    b = clamp(b, 0, 255)\n",
    "    return (r << 16) + (g << 8) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40be6d4-3af3-45e4-88f8-2db19e9b23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"rgb_int_to_ycbcr_ints.pkl\"):\n",
    "    with open(\"rgb_int_to_ycbcr_ints.pkl\", \"rb\") as f:\n",
    "        # Occupies a few GB of RAM\n",
    "        rgb_int_to_ycbcr_ints = pickle.load(f)\n",
    "else:\n",
    "    print(\"Allocation of reverse map...\")\n",
    "    rgb_int_to_ycbcr_ints = {i: [] for i in trange(2 ** 24)}\n",
    "    print(\"Calculation of reverse mapping...\")\n",
    "    for ycbcr_int in trange(2 ** 24):\n",
    "        rgb_int_to_ycbcr_ints[ycbcr_int_to_rgb_int(ycbcr_int)].append(ycbcr_int)\n",
    "    print(\"Conversion of list to tuple...\")\n",
    "    for ycbcr_int in trange(2 ** 24):\n",
    "        rgb_int_to_ycbcr_ints[ycbcr_int_to_rgb_int(ycbcr_int)] = tuple(rgb_int_to_ycbcr_ints[ycbcr_int_to_rgb_int(ycbcr_int)])\n",
    "    with open(\"rgb_int_to_ycbcr_ints.pkl\", \"wb\") as f:\n",
    "        pickle.dump(rgb_int_to_ycbcr_ints, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce7c098-8bc6-4a51-812f-a292eb9c3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_int_to_y_interval(rgb_int, pbar):\n",
    "    ycbcr_ints = rgb_int_to_ycbcr_ints[rgb_int]\n",
    "    ys = [(ycbcr_int >> 16) for ycbcr_int in ycbcr_ints]\n",
    "    pbar.update()\n",
    "    return sp.Interval(min(ys), max(ys))\n",
    "\n",
    "def rgb_int_to_cb_set(rgb_int, pbar):\n",
    "    ycbcr_ints = rgb_int_to_ycbcr_ints[rgb_int]\n",
    "    cbs = [((ycbcr_int >> 8) & 0xff) for ycbcr_int in ycbcr_ints]\n",
    "    pbar.update()\n",
    "    return set(cbs)\n",
    "\n",
    "def rgb_int_to_cr_set(rgb_int, pbar):\n",
    "    ycbcr_ints = rgb_int_to_ycbcr_ints[rgb_int]\n",
    "    crs = [(ycbcr_int & 0xff) for ycbcr_int in ycbcr_ints]\n",
    "    pbar.update()\n",
    "    return set(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472064a6-6464-426d-be51-a2023d16dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test1c\"  # test1c or test2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725a2e9-10de-4299-a2aa-d7b95dc28bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(f\"{file_name}.png\")\n",
    "rgb_channels = np.asarray(image).astype(int)\n",
    "rgb_int_image = (rgb_channels[:, :, 0] << 16) + (rgb_channels[:, :, 1] << 8) + (rgb_channels[:, :, 2])\n",
    "with tqdm(total=np.size(rgb_int_image)) as pbar:\n",
    "    bar_y_channel = np.vectorize(rgb_int_to_y_interval)(rgb_int_image, pbar)\n",
    "    with open(f\"{file_name}_bar_y_channel.pkl\", \"wb\") as f:\n",
    "        pickle.dump(bar_y_channel, f)\n",
    "del bar_y_channel\n",
    "\n",
    "with tqdm(total=np.size(rgb_int_image)) as pbar:\n",
    "    ddot_cb_channel = np.vectorize(rgb_int_to_cb_set)(rgb_int_image, pbar)\n",
    "    with open(f\"{file_name}_ddot_cb_channel.pkl\", \"wb\") as f:\n",
    "        pickle.dump(ddot_cb_channel, f)\n",
    "del ddot_cb_channel\n",
    "\n",
    "with tqdm(total=np.size(rgb_int_image)) as pbar:\n",
    "    ddot_cr_channel = np.vectorize(rgb_int_to_cr_set)(rgb_int_image, pbar)\n",
    "    with open(f\"{file_name}_ddot_cr_channel.pkl\", \"wb\") as f:\n",
    "        pickle.dump(ddot_cr_channel, f)\n",
    "del ddot_cr_channel\n",
    "        \n",
    "del rgb_int_to_y_interval\n",
    "del rgb_int_to_cb_set\n",
    "del rgb_int_to_cr_set\n",
    "del rgb_int_to_ycbcr_ints\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1edc3fc-ffb5-47dc-b962-6868932bebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{file_name}_bar_y_channel.pkl\", \"rb\") as f:\n",
    "    bar_y_channel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553544d6-892a-4560-a9b2-c30bb7e78edc",
   "metadata": {},
   "source": [
    "## 2.2 Chroma downsampling (broken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee155b1-c626-4d9a-ad15-64125626436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c stands in for cb or cr\n",
    "def bar_wij_given_c_xevenyeven(c, bar_wim1jm1, bar_wijm1, bar_wim1j):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - bar_wim1jm1.inf - 3 * bar_wijm1.inf - 3 * bar_wim1j.inf, 9)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - bar_wim1jm1.sup - 3 * bar_wijm1.sup - 3 * bar_wim1j.sup, 9))\n",
    "    )\n",
    "def bar_wim1j_given_c_xevenyeven(c, bar_wim1jm1, bar_wijm1, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - bar_wim1jm1.inf - 3 * bar_wijm1.inf - 9 * bar_wij.inf, 3)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - bar_wim1jm1.sup - 3 * bar_wijm1.sup - 9 * bar_wij.sup, 3))\n",
    "    )\n",
    "def bar_wijm1_given_c_xevenyeven(c, bar_wim1jm1, bar_wim1j, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - bar_wim1jm1.inf - 3 * bar_wim1j.inf - 9 * bar_wij.inf, 3)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - bar_wim1jm1.sup - 3 * bar_wim1j.sup - 9 * bar_wij.sup, 3))\n",
    "    )\n",
    "def bar_wim1jm1_given_c_xevenyeven(c, bar_wijm1, bar_wim1j, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(16 * c - 8 - 3 * bar_wijm1.inf - 3 * bar_wim1j.inf - 9 * bar_wij.inf),\n",
    "        sp.floor(16 * c + 7 - 3 * bar_wijm1.sup - 3 * bar_wim1j.sup - 9 * bar_wij.sup)\n",
    "    )\n",
    "\n",
    "def bar_wij_given_c_xoddyeven(c, bar_wim1jm1, bar_wijm1, bar_wim1j):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - 3 * bar_wim1jm1.inf - bar_wijm1.inf - 9 * bar_wim1j.inf, 3)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - 3 * bar_wim1jm1.sup - bar_wijm1.sup - 9 * bar_wim1j.sup, 3))\n",
    "    )\n",
    "def bar_wim1j_given_c_xoddyeven(c, bar_wim1jm1, bar_wijm1, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - 3 * bar_wim1jm1.inf - bar_wijm1.inf - 3 * bar_wij.inf, 9)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - 3 * bar_wim1jm1.sup - bar_wijm1.sup - 3 * bar_wij.sup, 9))\n",
    "    )\n",
    "def bar_wijm1_given_c_xoddyeven(c, bar_wim1jm1, bar_wim1j, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(16 * c - 8 - 3 * bar_wim1jm1.inf - 9 * bar_wim1j.inf - 3 * bar_wij.inf),\n",
    "        sp.floor(16 * c + 7 - 3 * bar_wim1jm1.sup - 9 * bar_wim1j.sup - 3 * bar_wij.sup)\n",
    "    )\n",
    "def bar_wim1jm1_given_c_xoddyeven(c, bar_wijm1, bar_wim1j, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - bar_wijm1.inf - 9 * bar_wim1j.inf - 3 * bar_wij.inf, 3)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - bar_wijm1.sup - 9 * bar_wim1j.sup - 3 * bar_wij.sup, 3))\n",
    "    )\n",
    "\n",
    "def bar_wij_given_c_xevenyodd(c, bar_wim1jm1, bar_wijm1, bar_wim1j):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - 3 * bar_wim1jm1.inf - 9 * bar_wijm1.inf - bar_wim1j.inf, 3)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - 3 * bar_wim1jm1.sup - 9 * bar_wijm1.sup - bar_wim1j.sup, 3))\n",
    "    )\n",
    "def bar_wim1j_given_c_xevenyodd(c, bar_wim1jm1, bar_wijm1, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(16 * c - 8 - 3 * bar_wim1jm1.inf - 9 * bar_wijm1.inf - 3 * bar_wij.inf),\n",
    "        sp.floor(16 * c + 7 - 3 * bar_wim1jm1.sup - 9 * bar_wijm1.sup - 3 * bar_wij.sup)\n",
    "    )\n",
    "def bar_wijm1_given_c_xevenyodd(c, bar_wim1jm1, bar_wim1j, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - 3 * bar_wim1jm1.inf - bar_wim1j.inf - 3 * bar_wij.inf, 9)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - 3 * bar_wim1jm1.sup - bar_wim1j.sup - 3 * bar_wij.sup, 9))\n",
    "    )\n",
    "def bar_wim1jm1_given_c_xevenyodd(c, bar_wijm1, bar_wim1j, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - 9 * bar_wijm1.inf - bar_wim1j.inf - 3 * bar_wij.inf, 3)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - 9 * bar_wijm1.sup - bar_wim1j.sup - 3 * bar_wij.sup, 3))\n",
    "    )\n",
    "\n",
    "def bar_wij_given_c_xoddyodd(c, bar_wim1jm1, bar_wijm1, bar_wim1j):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(16 * c - 8 - 9 * bar_wim1jm1.inf - 3 * bar_wijm1.inf - 3 * bar_wim1j.inf),\n",
    "        sp.floor(16 * c + 7 - 9 * bar_wim1jm1.sup - 3 * bar_wijm1.sup - 3 * bar_wim1j.sup)\n",
    "    )\n",
    "def bar_wim1j_given_c_xoddyodd(c, bar_wim1jm1, bar_wijm1, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - 9 * bar_wim1jm1.inf - 3 * bar_wijm1.inf - bar_wij.inf, 3)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - 9 * bar_wim1jm1.sup - 3 * bar_wijm1.sup - bar_wij.sup, 3))\n",
    "    )\n",
    "def bar_wijm1_given_c_xoddyodd(c, bar_wim1jm1, bar_wim1j, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - 9 * bar_wim1jm1.inf - 3 * bar_wim1j.inf - bar_wij.inf, 3)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - 9 * bar_wim1jm1.sup - 3 * bar_wim1j.sup - bar_wij.sup, 3))\n",
    "    )\n",
    "def bar_wim1jm1_given_c_xoddyodd(c, bar_wijm1, bar_wim1j, bar_wij):\n",
    "    return sp.Interval(\n",
    "        sp.ceiling(sp.Rational(16 * c - 8 - 3 * bar_wijm1.inf - 3 * bar_wim1j.inf - bar_wij.inf, 9)),\n",
    "        sp.floor(sp.Rational(16 * c + 7 - 3 * bar_wijm1.sup - 3 * bar_wim1j.sup - bar_wij.sup, 9))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f82b7-eafb-4159-b57a-510b3b8f37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_1(channel_setmat):  # either ddot_cb_channel or ddot_cr_channel\n",
    "    H, W = channel_setmat.shape\n",
    "    downsampled_intervals = np.full((H // 2 + 2, W // 2 + 2), sp.Interval(0, 255))\n",
    "    reverse = False\n",
    "    iter_n = 0\n",
    "    pbar = tqdm()\n",
    "    while True:\n",
    "        iter_n += 1\n",
    "        downsampled_intervals_old = np.copy(downsampled_intervals)\n",
    "        for x in (reversed(range(H)) if reverse else range(H)):\n",
    "            x_even = x % 2 == 0\n",
    "            i = x // 2 if x_even else (x + 1) // 2 + 1  # zero-indexing for range [-1, W//2] (python [0, W//2+2)), must +1; the i here is 1 more than the actual mathematical i\n",
    "            for y in (reversed(range(W)) if reverse else range(W)):\n",
    "                y_even = y % 2 == 0\n",
    "                j = y // 2 if y_even else (y + 1) // 2 + 1  # zero-indexing for range [-1, H//2] (python [0, H//2+2)), must +1; the j here is 1 more than the actual mathematical i\n",
    "                # c stands for either cb or cr\n",
    "                if x_even and y_even:\n",
    "                    diij_to_intersect = sp.Union(*[\n",
    "                        bar_wij_given_c_xevenyeven(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dim1j_to_intersect = sp.Union(*[\n",
    "                        bar_wim1j_given_c_xevenyeven(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dijm1_to_intersect = sp.Union(*[\n",
    "                        bar_wijm1_given_c_xevenyeven(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dim1jm1_to_intersect = sp.Union(*[\n",
    "                        bar_wim1jm1_given_c_xevenyeven(\n",
    "                            c, \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                elif (not x_even) and y_even:\n",
    "                    diij_to_intersect = sp.Union(*[\n",
    "                        bar_wij_given_c_xoddyeven(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dim1j_to_intersect = sp.Union(*[\n",
    "                        bar_wim1j_given_c_xoddyeven(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dijm1_to_intersect = sp.Union(*[\n",
    "                        bar_wijm1_given_c_xoddyeven(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dim1jm1_to_intersect = sp.Union(*[\n",
    "                        bar_wim1jm1_given_c_xoddyeven(\n",
    "                            c, \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                elif x_even and (not y_even):\n",
    "                    diij_to_intersect = sp.Union(*[\n",
    "                        bar_wij_given_c_xevenyodd(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dim1j_to_intersect = sp.Union(*[\n",
    "                        bar_wim1j_given_c_xevenyodd(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dijm1_to_intersect = sp.Union(*[\n",
    "                        bar_wijm1_given_c_xevenyodd(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dim1jm1_to_intersect = sp.Union(*[\n",
    "                        bar_wim1jm1_given_c_xevenyodd(\n",
    "                            c, \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                else:\n",
    "                    diij_to_intersect = sp.Union(*[\n",
    "                        bar_wij_given_c_xoddyodd(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dim1j_to_intersect = sp.Union(*[\n",
    "                        bar_wim1j_given_c_xoddyodd(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dijm1_to_intersect = sp.Union(*[\n",
    "                        bar_wijm1_given_c_xoddyodd(\n",
    "                            c, \n",
    "                            bar_wim1jm1=downsampled_intervals[i - 1, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                    dim1jm1_to_intersect = sp.Union(*[\n",
    "                        bar_wim1jm1_given_c_xoddyodd(\n",
    "                            c, \n",
    "                            bar_wijm1=downsampled_intervals[i, j - 1], \n",
    "                            bar_wim1j=downsampled_intervals[i - 1, j], \n",
    "                            bar_wij=downsampled_intervals[i, j]\n",
    "                        )\n",
    "                        for c in channel_setmat[x, y]\n",
    "                    ])\n",
    "                downsampled_intervals[i, j] = downsampled_intervals[i, j].intersect(diij_to_intersect)\n",
    "                downsampled_intervals[i - 1, j] = downsampled_intervals[i - 1, j].intersect(dim1j_to_intersect)\n",
    "                downsampled_intervals[i, j - 1] = downsampled_intervals[i, j - 1].intersect(dijm1_to_intersect)\n",
    "                downsampled_intervals[i - 1, j - 1] = downsampled_intervals[i - 1, j - 1].intersect(dim1jm1_to_intersect)\n",
    "        if np.all(downsampled_intervals == downsampled_intervals_old):\n",
    "            break\n",
    "        reverse = not reverse\n",
    "        pbar.update()\n",
    "    print(f\"Converged on the {iter_n}-th iteration\")\n",
    "    return downsampled_intervals[1:-1, 1:-1]  # remove padded regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119b963-16a4-4e2d-b3fe-d667cef46852",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test1c\"\n",
    "print(f\"Loading {file_name}_ddot_cb_channel.pkl ...\")\n",
    "with open(f\"{file_name}_ddot_cb_channel.pkl\", \"rb\") as f:\n",
    "    ddot_cb_channel = pickle.load(f)\n",
    "print(f\"Running algorithm_1...\")\n",
    "bar_cb_channel = algorithm_1(ddot_cb_channel)\n",
    "print(f\"Saving to {file_name}_bar_cb_channel.pkl ...\")\n",
    "with open(f\"{file_name}_bar_cb_channel.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bar_cb_channel, f)\n",
    "del bar_cb_channel\n",
    "del ddot_cb_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c4463-3e3b-4c4f-80ca-89c2220af62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"test2c\"\n",
    "print(f\"Loading {file_name}_ddot_cb_channel.pkl ...\")\n",
    "with open(f\"{file_name}_ddot_cb_channel.pkl\", \"rb\") as f:\n",
    "    ddot_cb_channel = pickle.load(f)\n",
    "print(f\"Running algorithm_1...\")\n",
    "bar_cb_channel = algorithm_1(ddot_cb_channel)\n",
    "print(f\"Saving to {file_name}_bar_cb_channel.pkl ...\")\n",
    "with open(f\"{file_name}_bar_cb_channel.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bar_cb_channel, f)\n",
    "del bar_cb_channel\n",
    "del ddot_cb_channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb7f688-fd67-4578-8326-dd3ff44a4042",
   "metadata": {},
   "source": [
    "## 2.3 Discrete cosine transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459568b6-0896-4357-96cc-b375abf5ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_interval_add(bar_p, alpha):\n",
    "    # (5a)\n",
    "    # Handling of empty intervals not yet done\n",
    "    return sp.Interval(bar_p.inf - alpha, bar_p.sup - alpha)\n",
    "    \n",
    "def invert_intervalmat_add(bar_p_mat, alpha):\n",
    "    return np.vectorize(invert_interval_add)(bar_p_mat, alpha)\n",
    "    \n",
    "def invert_interval_mult(bar_p, alpha):\n",
    "    # (5b)\n",
    "    # Handling of empty intervals not yet done\n",
    "    return sp.Interval(sp.ceiling(bar_p.inf / alpha), sp.floor(bar_p.sup / alpha))\n",
    "\n",
    "def invert_intervalmat_mult(bar_p_mat, alpha):\n",
    "    return np.vectorize(invert_interval_mult)(bar_p_mat, alpha)\n",
    "\n",
    "def invert_interval_divfloor(bar_p, alpha):\n",
    "    # (5c)\n",
    "    # Handling of empty intervals not yet done\n",
    "    return sp.Interval(bar_p.inf * alpha, bar_p.sup * alpha + (alpha - 1))\n",
    "\n",
    "def invert_intervalmat_divfloor(bar_p_mat, alpha):\n",
    "    return np.vectorize(invert_interval_divfloor)(bar_p_mat, alpha)\n",
    "\n",
    "def invert_intervalmat_matrixpremult(bar_y_mat, Tinv):\n",
    "    # T bar_x_mat = bar_y_mat\n",
    "    # bar_x_mat = Tinv bar_y_mat\n",
    "    # Given interval matrix bar_y_mat, find interval matrix bar_x_mat\n",
    "    \n",
    "    # assumes both bar_y_mat and Tinv are square matrices of the same shape\n",
    "    # (9a)\n",
    "    matrix_len = bar_y_mat.shape[0]\n",
    "    result = np.full((matrix_len, matrix_len), sp.EmptySet)\n",
    "    for i in range(matrix_len):\n",
    "        for j in range(matrix_len):\n",
    "            result[i, j] = sp.Interval(\n",
    "                sp.ceiling(sum(\n",
    "                    [Tinv[i, k] * (bar_y_mat[k, j].inf if Tinv[i, k] >= 0 else bar_y_mat[k, j].sup) for k in range(matrix_len)]\n",
    "                )),\n",
    "                sp.floor(sum(\n",
    "                    [Tinv[i, k] * (bar_y_mat[k, j].sup if Tinv[i, k] >= 0 else bar_y_mat[k, j].inf) for k in range(matrix_len)]\n",
    "                ))\n",
    "            )\n",
    "    return result\n",
    "\n",
    "def invert_intervalmat_matrixpostmult(bar_y_mat, Tinv):\n",
    "    # bar_x_mat T = bar_y_mat\n",
    "    # bar_x_mat = bar_y_mat Tinv\n",
    "    # Given interval matrix bar_y_mat, find interval matrix bar_x_mat\n",
    "    \n",
    "    # assumes both bar_y_mat and Tinv are square matrices of the same shape\n",
    "    # (9b), self-figured\n",
    "    matrix_len = bar_y_mat.shape[0]\n",
    "    result = np.full((matrix_len, matrix_len), sp.EmptySet)\n",
    "    for i in range(matrix_len):\n",
    "        for j in range(matrix_len):\n",
    "            result[i, j] = sp.Interval(\n",
    "                sp.ceiling(sum(\n",
    "                    [Tinv[k, j] * (bar_y_mat[i, k].inf if Tinv[k, j] >= 0 else bar_y_mat[i, k].sup) for k in range(matrix_len)]\n",
    "                )),\n",
    "                sp.floor(sum(\n",
    "                    [Tinv[k, j] * (bar_y_mat[i, k].sup if Tinv[k, j] >= 0 else bar_y_mat[i, k].inf) for k in range(matrix_len)]\n",
    "                ))\n",
    "            )\n",
    "    return result\n",
    "    \n",
    "def invert_interval_max(bar_x, a):\n",
    "    # (10a)\n",
    "    # Handling of empty intervals not yet done\n",
    "    return sp.Interval(-sp.oo if bar_x.inf <= a else bar_x.inf, bar_x.sup)\n",
    "\n",
    "def invert_intervalmat_max(bar_x_mat, a):\n",
    "    return np.vectorize(invert_interval_max)(bar_x_mat, a)\n",
    "    \n",
    "def invert_interval_min(bar_x, a):\n",
    "    # (10b)\n",
    "    # Handling of empty intervals not yet done\n",
    "    return sp.Interval(bar_x.inf, sp.oo if bar_x.sup >= a else bar_x.sup)\n",
    "\n",
    "def invert_intervalmat_min(bar_x_mat, a):\n",
    "    return np.vectorize(invert_interval_min)(bar_x_mat, a)\n",
    "\n",
    "def IDCT_intervalmat(bar_y_mat):\n",
    "    # bar_y_mat = IDCT(bar_x_mat)\n",
    "    # Given interval matrix bar_y_mat, find interval matrix bar_x_mat\n",
    "    \n",
    "    # result = bar_y_mat\n",
    "    # result = invert_intervalmat_max(result, 0)\n",
    "    # result = invert_intervalmat_min(result, 255)\n",
    "    # result = invert_intervalmat_divfloor(result, alpha=2 ** 18)\n",
    "    # result = invert_intervalmat_add(result, 2 ** 17)\n",
    "    result = np.vectorize(\n",
    "        lambda bar_y: sp.Interval(\n",
    "            -sp.oo if bar_y.inf == 0 else (bar_y.inf << 18) - 131072, \n",
    "            sp.oo if bar_y.sup == 255 else (bar_y.sup << 18) + 131071\n",
    "        )\n",
    "    )(bar_y_mat)\n",
    "    result = invert_intervalmat_matrixpostmult(result, Tinv=TTinv)\n",
    "    # result = invert_intervalmat_divfloor(result, alpha=2 ** 11)\n",
    "    # result = invert_intervalmat_add(result, 2 ** 10)\n",
    "    result = np.vectorize(\n",
    "        lambda bar_y: sp.Interval(\n",
    "            bar_y.inf * 2048 - 1024, \n",
    "            bar_y.sup * 2048 + 511\n",
    "        )\n",
    "    )(result)\n",
    "    result = invert_intervalmat_matrixpremult(result, Tinv=Tinv)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df9e3f-3c8a-4baa-92c7-765645b19759",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = sp.Matrix([\n",
    "    [8192, 11363, 10703, 9633, 8192, 6437, 4433, 2260],\n",
    "    [8192, 9633, 4433, -2259, -8192, -11362, -10704, -6436],\n",
    "    [8192, 6437, -4433, -11362, -8192, 2261, 10704, 9633],\n",
    "    [8192, 2260, -10703, -6436, 8192, 9633, -4433, -11363],\n",
    "    [8192, -2260, -10703, 6436, 8192, -9633, -4433, 11363],\n",
    "    [8192, -6437, -4433, 11362, -8192, -2261, 10704, -9633],\n",
    "    [8192, -9633, 4433, 2259, -8192, 11362, -10704, 6436],\n",
    "    [8192, -11363, 10703, -9633, 8192, -6437, 4433, -2260]\n",
    "])\n",
    "TTinv = T.T ** -1\n",
    "Tinv = T ** -1  # exact form, arbitrary precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f236fc9-ee49-4060-9fe0-e96c224c1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_dct_blockwise(channel, file_name):  # bar_y_channel, bar_cb_channel, or bar_cr_channel\n",
    "    H, W = channel.shape\n",
    "    assert H % 8 == 0 and W % 8 == 0\n",
    "    count_blocks_vertical = H // 8\n",
    "    count_blocks_horizontal = W // 8\n",
    "\n",
    "    # SLOW SOLUTION\n",
    "    dequantised_dct_coefficient_intervalchannel = np.full(channel.shape, None)\n",
    "    for block_i in trange(count_blocks_vertical):\n",
    "        for block_j in trange(count_blocks_horizontal, leave=False):\n",
    "            X = channel[(8 * block_i):(8 + 8 * block_i), (8 * block_j):(8 + 8 * block_j)]\n",
    "            dequantised_dct_coefficient_intervalchannel[(8 * block_i):(8 + 8 * block_i), (8 * block_j):(8 + 8 * block_j)] = IDCT_intervalmat(X)\n",
    "    \n",
    "    with open(f\"{file_name}_dequantised_dct_coefficient_intervalchannel.pkl\", \"wb\") as f:\n",
    "        pickle.dump(dequantised_dct_coefficient_intervalchannel, f)\n",
    "\n",
    "    # MULTIPROCESSING AND CONCURRENT.FUTURES SOLUTIONS ARE BROKEN\n",
    "    # def IDCT_wrapper(X):\n",
    "    #     return IDCT_intervalmat(np.vectorize(lambda v: sp.FiniteSet(v))(X))\n",
    "    \n",
    "    # progress = tqdm(total=count_blocks_vertical * count_blocks_horizontal)\n",
    "    # def callback_per_block(future, block_i, block_j):\n",
    "    #     dequantised_dct_coefficient_intervalchannel[(8 * block_i):(8 + 8 * block_i), (8 * block_j):(8 + 8 * block_j)] = future.result()\n",
    "    #     progress.update()\n",
    "    \n",
    "    # with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    #     for block_i in range(count_blocks_vertical):\n",
    "    #         for block_j in range(count_blocks_horizontal):\n",
    "    #             executor.submit(IDCT_wrapper, channel[(8 * block_i):(8 + 8 * block_i), (8 * block_j):(8 + 8 * block_j)]).add_done_callback(\n",
    "    #                 lambda future: callback_per_block(future, block_i, block_j)\n",
    "    #             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76dec9f-0639-4366-bf0c-1b2eb4984afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_dct_blockwise(bar_y_channel, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d1f65-f7f7-4672-b38a-db6f2f93c947",
   "metadata": {},
   "source": [
    "## 2.4 Determining possible quality factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c49fbe-aac0-4b4d-b7b0-4e0b99a27c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[{datetime.datetime.now().isoformat()}] Opening {file_name}_dequantised_dct_coefficient_intervalchannel.pkl ...\")\n",
    "with open(f\"{file_name}_dequantised_dct_coefficient_intervalchannel.pkl\", \"rb\") as f:\n",
    "    print(f\"[{datetime.datetime.now().isoformat()}] Unpickling {file_name}_dequantised_dct_coefficient_intervalchannel.pkl ...\")\n",
    "    dequantised_dct_coefficient_intervalchannel = pickle.load(f)\n",
    "    print(f\"[{datetime.datetime.now().isoformat()}] Done unpickling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b5f36-dca3-4f31-aee0-9372e0f64a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_is_possible(candidate_quality, minimal_infimum, maximal_supremum, dequantised_dct_coefficient_intervalchannel):\n",
    "    y_quantisation_table = generate_y_quantisation_table_given_quality(candidate_quality)\n",
    "    # multiples = np.vectorize(lambda v: generate_multiples_within_bounds(v, -1023, 1024))(y_quantisation_table)\n",
    "\n",
    "    H, W = dequantised_dct_coefficient_intervalchannel.shape\n",
    "    assert H % 8 == 0 and W % 8 == 0\n",
    "    count_blocks_vertical = H // 8\n",
    "    count_blocks_horizontal = W // 8\n",
    "    for block_i in trange(count_blocks_vertical, leave=False):\n",
    "        for block_j in trange(count_blocks_horizontal, leave=False):\n",
    "            bar_block = dequantised_dct_coefficient_intervalchannel[(8 * block_i):(8 + 8 * block_i), (8 * block_j):(8 + 8 * block_j)]\n",
    "            # This is an interval(bar) matrix \n",
    "            for i in reversed(range(8)):\n",
    "                for j in reversed(range(8)):\n",
    "                    inf = bar_block[i, j].inf\n",
    "                    sup = bar_block[i, j].sup\n",
    "                    q = y_quantisation_table[i, j]\n",
    "                    if round(inf / q) == round(sup / q) and ((inf < 0 and sup % q != 0) or (inf >= 0 and inf % q != 0)):\n",
    "                        return False\n",
    "                    # for multiple in multiples[i, j]:\n",
    "                    #     if bar_block[i, j].contains(multiple):\n",
    "                    #         continue\n",
    "                    #     return False  # all multiples not present; early terminate\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033d1e3-4cce-4166-8853-08a216d8c846",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_qualities = []\n",
    "print(f\"[{datetime.datetime.now().isoformat()}] Starting main loop...\")\n",
    "for candidate_quality in trange(1, 101):\n",
    "    # print(f\"[{datetime.datetime.now().isoformat()}] Testing candidate quality {candidate_quality}...\")\n",
    "    if quality_is_possible(candidate_quality, minimal_infimum, maximal_supremum, dequantised_dct_coefficient_intervalchannel):\n",
    "        print(f\"[{datetime.datetime.now().isoformat()}] quality {candidate_quality} is possible\")\n",
    "        possible_qualities.append(candidate_quality)\n",
    "    else:\n",
    "        print(f\"[{datetime.datetime.now().isoformat()}] quality {candidate_quality} disqualified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
